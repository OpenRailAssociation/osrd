import json
from pathlib import Path
from typing import Dict, List, Optional

import pytest
import requests

from fuzzer.fuzzer import create_scenario, get_infra

from .scenario import Scenario
from .services import EDITOAST_URL

REGRESSION_TESTS_DATA_FOLDER = Path(__file__).parent / "regression_tests_data"
REGRESSION_TESTS_JSON_FILES = [
    str(json_file.relative_to(REGRESSION_TESTS_DATA_FOLDER))
    for json_file in REGRESSION_TESTS_DATA_FOLDER.rglob("*.json")
]


"""
This file runs the regression tests generated by the fuzzer.
"""


def _load_infra(editoast_url: str, infra_id: int):
    """
    Send a request to preload the infra, raise a RuntimeError on failure
    """
    r = requests.post(editoast_url + f"infra/{infra_id}/load")
    if r.status_code // 100 != 2:
        if r.status_code // 100 == 4:
            return None
        raise RuntimeError(f"Infra load {r.status_code}: {r.content}")


def _schedule_with_payload(editoast_url: str, payload: Dict, accept_400: bool, scenario: Scenario) -> Optional[int]:
    """
    Send a schedule request with the given payload, raises an error if the request failed (unless we accept 400s).
    Returns the schedule id.
    """
    r = requests.post(editoast_url + f"/timetable/{scenario.timetable}/train_schedule/", json=payload)
    if r.status_code // 100 != 2:
        if r.status_code // 100 == 4 and accept_400:
            return None
        raise RuntimeError(f"Schedule error {r.status_code}: {r.content}")
    return r.json()[0]["id"]


def _stdcm_with_payload(editoast_url: str, payload: Dict, scenario: Scenario):
    """
    Send a stdcm request with the given payload, raises an error if the request failed.
    """
    url = editoast_url + f"/timetable/{scenario.timetable}/stdcm/?infra={scenario.infra}"
    r = requests.post(url, json=payload)
    if r.status_code // 100 != 2:
        raise RuntimeError(f"stdcm error {r.status_code}: {r.content}")


def _update_stdcm_payload(payload, rolling_stock_id: int):
    """
    Edit the given stdcm payload to replace the ids for the rolling stock.
    """
    payload["rolling_stock_id"] = rolling_stock_id


def _check_result(editoast_url: str, schedule_id: int, infra_id: int):
    """
    Get the /result/ of the given train id. The function doesn't return anything, it just raises any error
    """
    r = requests.get(f"{EDITOAST_URL}train_schedule/{schedule_id}/simulation/?infra_id={infra_id}")
    if r.status_code // 100 != 2 or r.json().get("status", "") != "success":
        raise RuntimeError(f"Schedule error {r.status_code}: {r.content}, id={schedule_id}")


def _apply_prelude(prelude: List, editoast_url: str, scenario: Scenario):
    """
    Send the requests from the test prelude to fill the timetable with trains
    """
    for train in prelude:
        assert "schedule_payload" in train

        schedule_payload = train["schedule_payload"]
        schedule_id = _schedule_with_payload(editoast_url, schedule_payload, accept_400=False, scenario=scenario)

        _check_result(editoast_url, schedule_id, scenario.infra)


def _reproduce_test(path_to_json: Path, scenario: Scenario, rolling_stock_id: int):
    """
    Reproduce one given test using the json generated by the fuzzer for one error case
    """
    fuzzer_output = json.loads(path_to_json.read_bytes())
    is_private_infra = fuzzer_output["infra_name"] not in ["small_infra", "Small Infra"]
    if is_private_infra:
        infra_id = get_infra(EDITOAST_URL, fuzzer_output["infra_name"])
        scenario = create_scenario(EDITOAST_URL, infra_id)
    _load_infra(EDITOAST_URL, scenario.infra)

    if fuzzer_output["error_type"] == "STDCM":
        _apply_prelude(fuzzer_output.get("prelude", []), EDITOAST_URL, scenario)
        payload = fuzzer_output["stdcm_payload"]
        _update_stdcm_payload(payload, rolling_stock_id)
        _stdcm_with_payload(EDITOAST_URL, payload, scenario)
        return

    stop_after_schedule = fuzzer_output["error_type"] == "SCHEDULE"

    payload = fuzzer_output["schedule_payload"]
    schedule_id = _schedule_with_payload(EDITOAST_URL, payload, stop_after_schedule, scenario)
    if stop_after_schedule:
        return

    _check_result(EDITOAST_URL, schedule_id, scenario.infra)


@pytest.mark.parametrize("file_name", REGRESSION_TESTS_JSON_FILES)
def test_regressions(file_name: str, small_scenario: Scenario, fast_rolling_stock: int):
    _reproduce_test(REGRESSION_TESTS_DATA_FOLDER / file_name, small_scenario, fast_rolling_stock)
